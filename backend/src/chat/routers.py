import asyncio
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from ..auth.dependencies import get_current_user
from ..core.config import settings
from ..core.database import get_db
from .models import ChatStatus
from .schema import (
    ChatHistoryResponse,
    ChatInteractionResponse,
    GenerateRoadmapResponse,
    QuestionnaireQuestionSchema,
    UserQuerySchema,
)
from .services import AIService, ChatService
from .services.ai import ChatHistoryItemSchema

router = APIRouter(
    prefix="/chats",
    tags=["chats"],
)


@router.post("/", response_model=ChatInteractionResponse)
async def chat_interaction(
    user_query: UserQuerySchema,
    db_session: AsyncSession = Depends(get_db),
    current_user=Depends(get_current_user),
):
    """Single endpoint to create or continue a chat.

    Behaviour:
    - If "session_id" does not exist in the DB, a new chat is created
      (using that value as chat.id), the title is generated by the AI,
      and the first clarifying question is returned.
    - If "session_id" exists, the provided "message" is stored as the
      answer to the last AI question, the next clarifying question is
      generated and returned. If the AI signals completion, no new
      question is returned and the chat is marked as completed.
    """

    if user_query.message is None or not user_query.message.strip():
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Message is required to interact with the chat",
        )
    if user_query.message and len(user_query.message) > 500:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Message must be 500 characters or fewer",
        )
    if user_query.session_id is None:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Session ID is required to interact with the chat",
        )

    # Try to fetch existing chat by the provided session_id (chat.id)
    chat = await ChatService.get_chat_by_id(db_session, user_query.session_id)

    ai_service = AIService()

    # New chat flow: create chat and generate a title
    # based on the first message
    if chat is None:
        title = await AIService.get_chat_title(user_query.message)
        chat = await ChatService.create_chat(
            db_session,
            title=title,
            initial_message=user_query.message,
            user_id=current_user.id,
            model_used=settings.openai_model_name,
            chat_id=user_query.session_id,
        )
        chat_history: list[ChatHistoryItemSchema] = []
    else:
        # Existing chat: store the user's answer against the last AI question
        if chat.question_answers is None:
            chat.question_answers = []

        if chat.question_answers:
            last_entry = chat.question_answers[-1]
            # Always treat the incoming message as the answer to the
            # most recently asked AI question.
            last_entry["answer"] = user_query.message

        # Build structured chat history for the AI from persisted Q/A
        chat_history: list[ChatHistoryItemSchema] = []
        for idx, item in enumerate(chat.question_answers or [], start=1):
            question = item.get("question")
            if not question:
                continue

            answer = item.get("answer") or ""
            order = item.get("order", idx)

            question_type = item.get("question_type", "text")
            question_options = item.get("options", [])
            question_text = (
                question.get("question", question)
                if isinstance(question, dict)
                else question
            )
            chat_history.append(
                ChatHistoryItemSchema(
                    question=question_text,
                    answer=answer,
                    order=order,
                    question_type=question_type,
                    options=question_options,
                )
            )

    if len(chat_history) >= settings.max_clarifying_questions:
        await ChatService.update_chat_status(
            db_session,
            chat,
            ChatStatus.COMPLETED,
        )
        return ChatInteractionResponse(
            session_id=chat.id,
            question="We will tailor the onboarding experience based on your answers. Thank you for providing the information!",
            completed=True,
            order=None,
            options=None,
            question_type=None,
        )

    # Ask the AI for the next clarifying question (or completion)
    next_question: QuestionnaireQuestionSchema | None = (
        await ai_service.generate_clarifying_question(
            user_message=user_query.message,
            chat_history=chat_history,
            session_id=str(chat.id),
        )
    )

    # If the AI signals completion, mark the chat as completed and stop
    if next_question is None:
        await ChatService.update_chat_status(
            db_session,
            chat,
            ChatStatus.COMPLETED,
        )
        return ChatInteractionResponse(
            session_id=chat.id,
            question=None,
            completed=True,
            order=None,
            options=None,
            question_type=None,
        )

    # Otherwise, append the new AI question with a null answer (to be
    # filled when the user responds next time)
    chat = await ChatService.add_question_answer(
        db_session,
        chat,
        question=next_question.question,
        answer=None,
        question_type=(
            next_question.question_type.value if next_question.question_type else "text"
        ),
        options=next_question.options,
    )

    return ChatInteractionResponse(
        session_id=chat.id,
        question=next_question.question,
        completed=False,
        order=next_question.order,
        options=next_question.options,
        question_type=(
            next_question.question_type.value if next_question.question_type else "text"
        ),
    )


@router.get("/{session_id}/history", response_model=ChatHistoryResponse)
async def get_chat_history(
    session_id: UUID,
    db_session: AsyncSession = Depends(get_db),
    current_user=Depends(get_current_user),
):
    """Return the full ordered chat history for a given session_id."""

    chat = await ChatService.get_chat_by_id(db_session, session_id)
    if chat is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Chat not found",
        )

    # Optional: enforce ownership so users cannot read others' chats.
    if chat.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not authorized to access this chat",
        )

    history: list[ChatHistoryItemSchema] = []
    turns = chat.question_answers or []
    # Ensure turns are sorted by `order` if present.
    turns_sorted = sorted(
        turns,
        key=lambda item: item.get("order", 0),
    )

    for idx, item in enumerate(turns_sorted, start=1):
        question_raw = item.get("question")
        if not question_raw:
            continue

        question = (
            question_raw.get("question", question_raw)
            if isinstance(question_raw, dict)
            else question_raw
        )
        answer = item.get("answer")
        order = item.get("order", idx)

        history.append(
            ChatHistoryItemSchema(
                question=question,
                answer=answer or "",
                order=order,
            )
        )

    return ChatHistoryResponse(
        session_id=chat.id,
        title=chat.title,
        status=chat.status,
        history=history,
    )


@router.post("/{session_id}/generate-roadmap", response_model=GenerateRoadmapResponse)
async def generate_roadmap(
    session_id: UUID,
    db_session: AsyncSession = Depends(get_db),
    current_user=Depends(get_current_user),
):
    """Trigger roadmap curation for a completed chat session.

    The actual work runs as an ``asyncio`` background task that publishes
    progress via Redis pub/sub.  The client should open a WebSocket to
    ``/ws/roadmap/{session_id}`` to receive live updates.
    """
    chat = await ChatService.get_chat_by_id(db_session, session_id)
    if chat is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Chat not found",
        )

    if chat.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not authorized to access this chat",
        )

    if chat.status != ChatStatus.COMPLETED:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Chat is not completed yet. Cannot generate roadmap.",
        )

    chat_data = {
        "title": chat.title,
        "initial_message": chat.initial_message,
        "question_answers": chat.question_answers or [],
    }

    # Fire background task with proper tracking
    from ..engine.entrypoint import _running_tasks, curate_roadmap

    task = asyncio.create_task(curate_roadmap(str(session_id), chat_data))
    _running_tasks.add(task)
    task.add_done_callback(_running_tasks.discard)

    return GenerateRoadmapResponse(
        session_id=chat.id,
        status="pending",
        message="Roadmap generation started. Connect to the WebSocket for live progress.",
    )
